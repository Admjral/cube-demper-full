"""
–°–∫—Ä–µ–π–ø–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂ –ø–æ –¥–Ω—è–º
API: /api/v1/niche/product/statisticLineDay

–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∑–∞ 2025 –≥–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path

import httpx

BASE_URL = "https://app.algatop.kz"
AUTH_COOKIE = "s%3A35528_06c4dd62-9e8b-4bfb-b5a7-5036bbb75312.aQ3YzCxRlRJ5A%2BQCVZnQldgJFJ1VwKfkMS3EEDAaH2w"

DATA_DIR = Path(__file__).parent.parent / "data"


def get_headers():
    return {
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://app.algatop.kz/niche",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }


async def get_available_periods(client: httpx.AsyncClient) -> dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤"""
    print("üìÖ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤...")

    response = await client.get(
        "/api/v1/niche/period",
        headers=get_headers()
    )

    if response.status_code == 200:
        data = response.json()
        print(f"‚úÖ –ü–µ—Ä–∏–æ–¥—ã –ø–æ–ª—É—á–µ–Ω—ã: {json.dumps(data, indent=2, ensure_ascii=False)[:500]}")
        return data
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
        return {}


async def get_product_daily_stats(
    client: httpx.AsyncClient,
    product_code: str,
    start_date: str = "20250101",
    end_date: str = "20251231"
) -> list:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–¥–∞–∂ —Ç–æ–≤–∞—Ä–∞"""

    response = await client.get(
        "/api/v1/niche/product/statisticLineDay",
        params={
            "code": product_code,
            "startDate": start_date,
            "endDate": end_date
        },
        headers=get_headers()
    )

    if response.status_code == 200:
        data = response.json()
        if isinstance(data, dict) and data.get("success"):
            return data.get("data", [])
        return data if isinstance(data, list) else []
    return []


async def scrape_product_history(max_products: int = 100):
    """–°–∫—Ä–µ–π–ø–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ–¥–∞–∂ –¥–ª—è —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤"""

    print("="*60)
    print("–°–ö–†–ï–ô–ü–ò–ù–ì –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–• –ü–†–û–î–ê–ñ")
    print("="*60)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
    products_file = sorted(DATA_DIR.glob("algatop_products_*.json"))[-1]
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é —Ç–æ–≤–∞—Ä—ã: {products_file.name}")

    with open(products_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    products = data.get("products", [])
    print(f"‚úÖ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")

    # –ë–µ—Ä—ë–º —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    products_sorted = sorted(products, key=lambda x: x.get("sale_qty", 0), reverse=True)
    top_products = products_sorted[:max_products]

    print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø-{len(top_products)} —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")

    async with httpx.AsyncClient(
        base_url=BASE_URL,
        timeout=60.0,
        cookies={"auth": AUTH_COOKIE}
    ) as client:

        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
        periods = await get_available_periods(client)

        # –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        all_history = []

        for i, product in enumerate(top_products, 1):
            product_code = product.get("product_code")
            product_name = product.get("product_name", "")[:50]
            category = product.get("_category_name", "")

            print(f"\n[{i}/{len(top_products)}] {product_name}...")

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ 2025 –≥–æ–¥
            history = await get_product_daily_stats(
                client,
                product_code,
                start_date="20250101",
                end_date="20251231"
            )

            if history:
                all_history.append({
                    "product_code": product_code,
                    "product_name": product.get("product_name"),
                    "category": category,
                    "sale_qty_month": product.get("sale_qty"),
                    "review_qty": product.get("review_qty"),
                    "daily_stats": history
                })
                print(f"  ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(history)} –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö")
            else:
                print(f"  ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

            await asyncio.sleep(0.3)

            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if i % 20 == 0:
                save_history(all_history, f"history_checkpoint_{i}.json")

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_history(all_history, "product_daily_history.json")

    print(f"\n" + "="*60)
    print(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: —Å–æ–±—Ä–∞–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è {len(all_history)} —Ç–æ–≤–∞—Ä–æ–≤")
    print("="*60)

    return all_history


def save_history(history: list, filename: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤ JSON"""
    filepath = DATA_DIR / filename

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump({
            "scraped_at": datetime.now().isoformat(),
            "total_products": len(history),
            "products": history
        }, f, ensure_ascii=False, indent=2)

    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")


async def analyze_sample():
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("="*60)
    print("–ê–ù–ê–õ–ò–ó –ü–†–ò–ú–ï–†–ê –î–ù–ï–í–ù–´–• –î–ê–ù–ù–´–•")
    print("="*60)

    async with httpx.AsyncClient(
        base_url=BASE_URL,
        timeout=60.0,
        cookies={"auth": AUTH_COOKIE}
    ) as client:

        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–∏–æ–¥—ã
        periods = await get_available_periods(client)

        # –ü—Ä–∏–º–µ—Ä —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        sample_code = "124522298"
        print(f"\nüì¶ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä: {sample_code}")

        history = await get_product_daily_stats(
            client,
            sample_code,
            start_date="20250101",
            end_date="20250228"
        )

        if history:
            print(f"\n‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(history)} –∑–∞–ø–∏—Å–µ–π")
            print("\n–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 5):")
            for item in history[:5]:
                print(f"  {json.dumps(item, ensure_ascii=False)}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä
            with open(DATA_DIR / "sample_daily_stats.json", 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            print(f"\nüíæ –ü—Ä–∏–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω: sample_daily_stats.json")
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã")


async def main():
    # –°–Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä
    await analyze_sample()

    # –ó–∞—Ç–µ–º —Å–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —Ç–æ–ø-100 —Ç–æ–≤–∞—Ä–æ–≤
    # await scrape_product_history(max_products=100)


if __name__ == "__main__":
    asyncio.run(main())
