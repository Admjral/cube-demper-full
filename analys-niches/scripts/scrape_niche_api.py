"""
–°–∫—Ä–µ–π–ø–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –Ω–∏—à —á–µ—Ä–µ–∑ HTTP API

API Endpoints:
- /api/v1/niche/categoryListStatistic - —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- /api/v1/niche/product - —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
- /api/v1/niche/sublingsCategory - –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
"""

import asyncio
import csv
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from urllib.parse import urlencode, quote

import httpx
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ credentials
load_dotenv(Path(__file__).parent.parent / ".env")

BASE_URL = "https://app.algatop.kz"

# Auth cookie –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
AUTH_COOKIE = "s%3A35528_06c4dd62-9e8b-4bfb-b5a7-5036bbb75312.aQ3YzCxRlRJ5A%2BQCVZnQldgJFJ1VwKfkMS3EEDAaH2w"

# –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
DATA_DIR = Path(__file__).parent.parent / "data"
DATA_DIR.mkdir(exist_ok=True)


class NicheDataAPI:
    def __init__(self):
        self.client = httpx.AsyncClient(
            base_url=BASE_URL,
            timeout=120.0,
            follow_redirects=True,
            cookies={"auth": AUTH_COOKIE}
        )
        self.categories = []
        self.products = []

    def _get_headers(self) -> dict:
        return {
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
            "Referer": "https://app.algatop.kz/niche",
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36"
        }

    async def get_categories(self, start_date: str = None, end_date: str = None) -> list:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
        print("üìÇ –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")

        if not start_date:
            end = datetime.now()
            start = end - timedelta(days=30)
            start_date = start.strftime("%Y%m%d")
            end_date = end.strftime("%Y%m%d")

        params = {
            "startDate": start_date,
            "endDate": end_date
        }

        response = await self.client.get(
            "/api/v1/niche/categoryListStatistic",
            params=params,
            headers=self._get_headers()
        )

        if response.status_code == 200:
            data = response.json()
            self.categories = data if isinstance(data, list) else data.get("data", data.get("categories", []))
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(self.categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
            return self.categories
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
            return []

    async def get_subcategories(self, category_code: str) -> list:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        response = await self.client.get(
            "/api/v1/niche/sublingsCategory",
            params={"categoryCode": category_code},
            headers=self._get_headers()
        )

        if response.status_code == 200:
            data = response.json()
            return data if isinstance(data, list) else data.get("data", [])
        return []

    async def get_products(
        self,
        category_id: str,
        start_date: str = None,
        end_date: str = None,
        page: int = 1,
        sort_type: str = "revenue",
        sort_direction: str = "desc"
    ) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""

        if not start_date:
            end = datetime.now()
            start = end - timedelta(days=30)
            start_date = start.strftime("%Y%m%d")
            end_date = end.strftime("%Y%m%d")

        sort_json = json.dumps({
            "type": sort_type,
            "direction": sort_direction,
            "typeName": "–ü–æ –≤—ã—Ä—É—á–∫–µ" if sort_type == "revenue" else "–ü–æ –ø—Ä–æ–¥–∞–∂–∞–º"
        })

        params = {
            "startDate": start_date,
            "endDate": end_date,
            "page": page,
            "filter": "{}",
            "categoryId": category_id,
            "sort": sort_json,
            "categoryType": ""
        }

        response = await self.client.get(
            "/api/v1/niche/product",
            params=params,
            headers=self._get_headers()
        )

        if response.status_code == 200:
            data = response.json()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º products.lines –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
            if isinstance(data, dict) and data.get("success"):
                products_data = data.get("data", {})
                if isinstance(products_data, dict):
                    products = products_data.get("products", {})
                    if isinstance(products, dict):
                        lines = products.get("lines", [])
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        total_pages = products.get("totalPages", 1)
                        return {"products": lines, "totalPages": total_pages}
            return data
        else:
            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ {response.status_code}: {response.text[:200]}")
            return {}

    async def get_all_products_in_category(
        self,
        category_id: str,
        category_name: str,
        max_pages: int = 100,
        start_date: str = None,
        end_date: str = None
    ) -> list:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)"""
        all_products = []
        page = 1

        while page <= max_pages:
            data = await self.get_products(
                category_id=category_id,
                start_date=start_date,
                end_date=end_date,
                page=page
            )

            products = data.get("products", [])
            if not products:
                break

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for p in products:
                p["_category_id"] = category_id
                p["_category_name"] = category_name

            all_products.extend(products)
            print(f"    –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: +{len(products)} —Ç–æ–≤–∞—Ä–æ–≤ (–≤—Å–µ–≥–æ: {len(all_products)})")

            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ 20 —Ç–æ–≤–∞—Ä–æ–≤ - —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            if len(products) < 20:
                break

            page += 1
            await asyncio.sleep(0.3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

        return all_products

    async def scrape_all(
        self,
        max_categories: int = None,
        max_pages_per_category: int = 100,
        include_subcategories: bool = True
    ):
        """–ü–æ–ª–Ω—ã–π —Å–∫—Ä–µ–π–ø–∏–Ω–≥ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        print("\n" + "="*60)
        print("–ü–û–õ–ù–´–ô –°–ö–†–ï–ô–ü–ò–ù–ì ALGATOP")
        print("="*60)

        # –î–∞—Ç—ã: –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
        end = datetime.now()
        start = end - timedelta(days=30)
        start_date = start.strftime("%Y%m%d")
        end_date = end.strftime("%Y%m%d")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date} - {end_date}")

        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        categories = await self.get_categories(start_date, end_date)
        if not categories:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
            return

        if max_categories:
            categories = categories[:max_categories]

        all_products = []
        all_categories_data = []

        for i, cat in enumerate(categories, 1):
            cat_id = cat.get("category_id", cat.get("id", cat.get("code")))
            cat_name = cat.get("category_name", cat.get("name", f"Category_{cat_id}"))
            has_subcategories = cat.get("is_has_subcategory", 0) == 1

            print(f"\n[{i}/{len(categories)}] üìÅ {cat_name} (ID: {cat_id})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            all_categories_data.append(cat)

            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–≤–∞—Ä—ã –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–±–µ–∑ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π)
            products = await self.get_all_products_in_category(
                category_id=cat_id,
                category_name=cat_name,
                max_pages=max_pages_per_category,
                start_date=start_date,
                end_date=end_date
            )
            all_products.extend(products)
            print(f"  ‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")

            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            if i % 5 == 0:
                print(f"\nüíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ({len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤)...")
                self.products = all_products
                await self.save_to_json(f"products_checkpoint_{i}.json")

            await asyncio.sleep(0.5)

        self.products = all_products
        self.categories = all_categories_data

        print(f"\n" + "="*60)
        print(f"‚úÖ –°–ö–†–ï–ô–ü–ò–ù–ì –ó–ê–í–ï–†–®–Å–ù")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(all_categories_data)}")
        print(f"   –¢–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
        print("="*60)

        return all_products

    async def save_to_csv(self, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV"""
        if not filename:
            filename = f"algatop_products_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

        filepath = DATA_DIR / filename

        if not self.products:
            print("‚ö†Ô∏è –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏
        all_keys = set()
        for p in self.products:
            all_keys.update(p.keys())

        headers = sorted(list(all_keys))

        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=headers)
            writer.writeheader()
            for product in self.products:
                writer.writerow(product)

        print(f"\nüíæ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filepath}")
        print(f"   –¢–æ–≤–∞—Ä–æ–≤: {len(self.products)}")

    async def save_to_json(self, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        if not filename:
            filename = f"algatop_products_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        filepath = DATA_DIR / filename

        data = {
            "scraped_at": datetime.now().isoformat(),
            "total_categories": len(self.categories),
            "total_products": len(self.products),
            "categories": self.categories,
            "products": self.products
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"üíæ JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filepath}")

    async def close(self):
        await self.client.aclose()


async def main():
    print("=" * 60)
    print("ALGATOP API SCRAPER")
    print("=" * 60)

    api = NicheDataAPI()

    try:
        # –ü–æ–ª–Ω—ã–π —Å–∫—Ä–µ–π–ø–∏–Ω–≥ - 500 —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (25 —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ 20)
        await api.scrape_all(
            max_categories=None,  # –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            max_pages_per_category=25,  # 25 —Å—Ç—Ä–∞–Ω–∏—Ü √ó 20 = 500 —Ç–æ–≤–∞—Ä–æ–≤
            include_subcategories=False
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await api.save_to_json()
        await api.save_to_csv()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á—Ç–æ —É—Å–ø–µ–ª–∏ —Å–æ–±—Ä–∞—Ç—å
        if api.products:
            print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            await api.save_to_json("products_partial.json")
            await api.save_to_csv("products_partial.csv")

    finally:
        await api.close()


if __name__ == "__main__":
    asyncio.run(main())
